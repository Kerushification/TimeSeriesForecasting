{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Store', 'Date', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2',\n",
      "       'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment',\n",
      "       'IsHoliday'],\n",
      "      dtype='object')\n",
      "Index(['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file1 = 'CSV/features.csv'\n",
    "file2 = 'CSV/train.csv'\n",
    "\n",
    "full_table1 = pd.read_csv(file1)\n",
    "full_table2 = pd.read_csv(file2)\n",
    "\n",
    "print(full_table1.columns)\n",
    "print(full_table2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2   \n",
      "0      1  05/02/2010        42.31       2.572        NaN        NaN  \\\n",
      "1      1  05/02/2010        42.31       2.572        NaN        NaN   \n",
      "2      1  05/02/2010        42.31       2.572        NaN        NaN   \n",
      "3      1  05/02/2010        42.31       2.572        NaN        NaN   \n",
      "4      1  05/02/2010        42.31       2.572        NaN        NaN   \n",
      "\n",
      "   MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  Dept   \n",
      "0        NaN        NaN        NaN  211.096358         8.106      False     1  \\\n",
      "1        NaN        NaN        NaN  211.096358         8.106      False     2   \n",
      "2        NaN        NaN        NaN  211.096358         8.106      False     3   \n",
      "3        NaN        NaN        NaN  211.096358         8.106      False     4   \n",
      "4        NaN        NaN        NaN  211.096358         8.106      False     5   \n",
      "\n",
      "   Weekly_Sales  \n",
      "0      24924.50  \n",
      "1      50605.27  \n",
      "2      13740.12  \n",
      "3      39954.04  \n",
      "4      32229.38  \n"
     ]
    }
   ],
   "source": [
    "#Merging tables\n",
    "merged_data = pd.merge(full_table1, full_table2, on=[\"Store\", \"Date\", \"IsHoliday\"])\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Weekly_Sales  Temperature  Fuel_Price  IsHoliday\n",
      "0  05/02/2010      24924.50        42.31       2.572      False\n",
      "1  05/02/2010      50605.27        42.31       2.572      False\n",
      "2  05/02/2010      13740.12        42.31       2.572      False\n",
      "3  05/02/2010      39954.04        42.31       2.572      False\n",
      "4  05/02/2010      32229.38        42.31       2.572      False\n"
     ]
    }
   ],
   "source": [
    "#Creating a new data frame with only desired variables\n",
    "desired_vars = {\n",
    "    \"Date\":merged_data['Date'],\n",
    "    \"Weekly_Sales\": merged_data[\"Weekly_Sales\"],\n",
    "    \"Temperature\": merged_data[\"Temperature\"],\n",
    "    \"Fuel_Price\": merged_data[\"Fuel_Price\"],\n",
    "    \"IsHoliday\": merged_data[\"IsHoliday\"]\n",
    "}\n",
    "\n",
    "data_table = pd.DataFrame(desired_vars)\n",
    "print(data_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data\n",
    "train_data = data_table[data_table[\"Date\"] < \"2012-01-01\"]\n",
    "test_data = data_table[data_table[\"Date\"] >= \"2012-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3804\\2772326072.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[\"IsHoliday\"] = train_data[\"IsHoliday\"].astype(int)\n",
      "c:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     SARIMAX Results                                      \n",
      "==========================================================================================\n",
      "Dep. Variable:                       Weekly_Sales   No. Observations:               280198\n",
      "Model:             SARIMAX(1, 1, 1)x(1, 1, 1, 12)   Log Likelihood            -3207921.857\n",
      "Date:                            Tue, 23 May 2023   AIC                        6415859.714\n",
      "Time:                                    00:20:31   BIC                        6415944.059\n",
      "Sample:                                         0   HQIC                       6415884.181\n",
      "                                         - 280198                                         \n",
      "Covariance Type:                              opg                                         \n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Temperature   -57.3380     16.425     -3.491      0.000     -89.531     -25.145\n",
      "Fuel_Price   5690.2425    853.128      6.670      0.000    4018.143    7362.342\n",
      "IsHoliday    -764.4517    594.547     -1.286      0.199   -1929.743     400.839\n",
      "ar.L1           0.3664      0.003    145.324      0.000       0.361       0.371\n",
      "ma.L1          -0.9950      0.000  -2022.445      0.000      -0.996      -0.994\n",
      "ar.S.L12       -0.0155      0.004     -3.888      0.000      -0.023      -0.008\n",
      "ma.S.L12       -0.9993      0.000  -4474.061      0.000      -1.000      -0.999\n",
      "sigma2       9.001e+08      0.016   5.74e+10      0.000       9e+08       9e+08\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                 741.74   Jarque-Bera (JB):           1237452.01\n",
      "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.51   Skew:                             2.37\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        12.14\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "[2] Covariance matrix is singular or near-singular, with condition number 1.65e+25. Standard errors may be unstable.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "#Convert IsHoliday bool type to int\n",
    "train_data[\"IsHoliday\"] = train_data[\"IsHoliday\"].astype(int)\n",
    "\n",
    "# Define exogenous variables\n",
    "exog_vars = [\"Temperature\", \"Fuel_Price\", \"IsHoliday\"]\n",
    "\n",
    "# Create SARIMAX model\n",
    "model = sm.tsa.SARIMAX(train_data[\"Weekly_Sales\"], exog=train_data[exog_vars],\n",
    "                       order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#Making predioctions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#Forecast future values\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m forecast \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39;49mget_forecast(steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(test_data), exog\u001b[39m=\u001b[39;49mtest_data[exog_vars])\n\u001b[0;32m      5\u001b[0m \u001b[39m# Extract the predicted values\u001b[39;00m\n\u001b[0;32m      6\u001b[0m predicted_values \u001b[39m=\u001b[39m forecast\u001b[39m.\u001b[39mpredicted_mean\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3417\u001b[0m, in \u001b[0;36mMLEResults.get_forecast\u001b[1;34m(self, steps, signal_only, **kwargs)\u001b[0m\n\u001b[0;32m   3415\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3416\u001b[0m     end \u001b[39m=\u001b[39m steps\n\u001b[1;32m-> 3417\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_prediction(start\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnobs, end\u001b[39m=\u001b[39;49mend,\n\u001b[0;32m   3418\u001b[0m                            signal_only\u001b[39m=\u001b[39;49msignal_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3355\u001b[0m, in \u001b[0;36mMLEResults.get_prediction\u001b[1;34m(self, start, end, dynamic, information_set, signal_only, index, exog, extend_model, extend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   3352\u001b[0m     extend_model \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mexog \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m\n\u001b[0;32m   3353\u001b[0m                     \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_results\u001b[39m.\u001b[39mtime_invariant)\n\u001b[0;32m   3354\u001b[0m \u001b[39mif\u001b[39;00m out_of_sample \u001b[39mand\u001b[39;00m extend_model:\n\u001b[1;32m-> 3355\u001b[0m     kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49m_get_extension_time_varying_matrices(\n\u001b[0;32m   3356\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams, exog, out_of_sample, extend_kwargs,\n\u001b[0;32m   3357\u001b[0m         transformed\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, includes_fixed\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   3359\u001b[0m \u001b[39m# Make sure the model class has the current parameters\u001b[39;00m\n\u001b[0;32m   3360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams, transformed\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, includes_fixed\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1739\u001b[0m, in \u001b[0;36mSARIMAX._get_extension_time_varying_matrices\u001b[1;34m(self, params, exog, out_of_sample, extend_kwargs, transformed, includes_fixed, **kwargs)\u001b[0m\n\u001b[0;32m   1736\u001b[0m     extend_kwargs\u001b[39m.\u001b[39msetdefault(\n\u001b[0;32m   1737\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtrend_offset\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrend_offset \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnobs)\n\u001b[0;32m   1738\u001b[0m extend_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mvalidate_specification\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1739\u001b[0m mod_extend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclone(\n\u001b[0;32m   1740\u001b[0m     endog\u001b[39m=\u001b[39;49mtmp_endog, exog\u001b[39m=\u001b[39;49mtmp_exog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextend_kwargs)\n\u001b[0;32m   1741\u001b[0m mod_extend\u001b[39m.\u001b[39mupdate(params, transformed\u001b[39m=\u001b[39mtransformed,\n\u001b[0;32m   1742\u001b[0m                   includes_fixed\u001b[39m=\u001b[39mincludes_fixed,)\n\u001b[0;32m   1744\u001b[0m \u001b[39m# Retrieve the extensions to the time-varying system matrices and\u001b[39;00m\n\u001b[0;32m   1745\u001b[0m \u001b[39m# put them in kwargs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:813\u001b[0m, in \u001b[0;36mSARIMAX.clone\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclone\u001b[39m(\u001b[39mself\u001b[39m, endog, exog\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 813\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_clone_from_init_kwds(endog, exog\u001b[39m=\u001b[39;49mexog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:295\u001b[0m, in \u001b[0;36mMLEModel._clone_from_init_kwds\u001b[1;34m(self, endog, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mk_exog\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mexog\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCloning a model with an exogenous component\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    292\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m requires specifying a new exogenous array using\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    293\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m the `exog` argument.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 295\u001b[0m mod \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m(endog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49muse_kwargs)\n\u001b[0;32m    296\u001b[0m \u001b[39mreturn\u001b[39;00m mod\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:328\u001b[0m, in \u001b[0;36mSARIMAX.__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, trend, measurement_error, time_varying_regression, mle_regression, simple_differencing, enforce_stationarity, enforce_invertibility, hamilton_representation, concentrate_scale, trend_offset, use_exact_diffuse, dates, freq, missing, validate_specification, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m),\n\u001b[0;32m    319\u001b[0m              seasonal_order\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m), trend\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    320\u001b[0m              measurement_error\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, time_varying_regression\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m              freq\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, missing\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m, validate_specification\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    326\u001b[0m              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spec \u001b[39m=\u001b[39m SARIMAXSpecification(\n\u001b[0;32m    329\u001b[0m         endog, exog\u001b[39m=\u001b[39;49mexog, order\u001b[39m=\u001b[39;49morder, seasonal_order\u001b[39m=\u001b[39;49mseasonal_order,\n\u001b[0;32m    330\u001b[0m         trend\u001b[39m=\u001b[39;49mtrend, enforce_stationarity\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, enforce_invertibility\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    331\u001b[0m         concentrate_scale\u001b[39m=\u001b[39;49mconcentrate_scale, dates\u001b[39m=\u001b[39;49mdates, freq\u001b[39m=\u001b[39;49mfreq,\n\u001b[0;32m    332\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing, validate_specification\u001b[39m=\u001b[39;49mvalidate_specification)\n\u001b[0;32m    333\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_params \u001b[39m=\u001b[39m SARIMAXParams(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spec)\n\u001b[0;32m    335\u001b[0m     \u001b[39m# Save given orders\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\arima\\specification.py:446\u001b[0m, in \u001b[0;36mSARIMAXSpecification.__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, ar_order, diff, ma_order, seasonal_ar_order, seasonal_diff, seasonal_ma_order, seasonal_periods, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[0;32m    441\u001b[0m         exog \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mc_[trend_data, exog]\n\u001b[0;32m    443\u001b[0m \u001b[39m# Create an underlying time series model, to handle endog / exog,\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m# especially validating shapes, retrieving names, and potentially\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39m# providing us with a time series index\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m TimeSeriesModel(endog, exog\u001b[39m=\u001b[39;49mexog, dates\u001b[39m=\u001b[39;49mdates, freq\u001b[39m=\u001b[39;49mfreq,\n\u001b[0;32m    447\u001b[0m                               missing\u001b[39m=\u001b[39;49mmissing)\n\u001b[0;32m    448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m faux_endog \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model\u001b[39m.\u001b[39mendog\n\u001b[0;32m    449\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model\u001b[39m.\u001b[39mexog\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:470\u001b[0m, in \u001b[0;36mTimeSeriesModel.__init__\u001b[1;34m(self, endog, exog, dates, freq, missing, **kwargs)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    468\u001b[0m     \u001b[39mself\u001b[39m, endog, exog\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dates\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, freq\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, missing\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    469\u001b[0m ):\n\u001b[1;32m--> 470\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, missing\u001b[39m=\u001b[39;49mmissing, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    472\u001b[0m     \u001b[39m# Date handling in indexes\u001b[39;00m\n\u001b[0;32m    473\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_dates(dates, freq)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    271\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mmissing\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mhasconst\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m     96\u001b[0m                               \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexog\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_handle_data\u001b[39m(\u001b[39mself\u001b[39m, endog, exog, missing, hasconst, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[39m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    136\u001b[0m     \u001b[39m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[39m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[39mreturn\u001b[39;00m klass(endog, exog\u001b[39m=\u001b[39;49mexog, missing\u001b[39m=\u001b[39;49mmissing, hasconst\u001b[39m=\u001b[39;49mhasconst,\n\u001b[0;32m    676\u001b[0m              \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\data.py:88\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconst_idx \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_constant(hasconst)\n\u001b[0;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_integrity()\n\u001b[0;32m     90\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\data.py:133\u001b[0m, in \u001b[0;36mModelData._handle_constant\u001b[1;34m(self, hasconst)\u001b[0m\n\u001b[0;32m    131\u001b[0m check_implicit \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    132\u001b[0m exog_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39;49misfinite(exog_max)\u001b[39m.\u001b[39mall():\n\u001b[0;32m    134\u001b[0m     \u001b[39mraise\u001b[39;00m MissingDataError(\u001b[39m'\u001b[39m\u001b[39mexog contains inf or nans\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    135\u001b[0m exog_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "#Making predioctions\n",
    "#Forecast future values\n",
    "forecast = results.get_forecast(steps=len(test_data), exog=test_data[exog_vars])\n",
    "\n",
    "# Extract the predicted values\n",
    "predicted_values = forecast.predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating Model\n",
    "#Compare predicted values with actual values\n",
    "mse = ((predicted_values - test_data[\"Weekly_Sales\"]) ** 2).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
